{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e89edb68-ed02-4c2a-884e-254e8291ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huggingface ASR dataset to be tested\n",
    "DATASET = 'google/fleurs'\n",
    "LANGUAGE = 'en_us'\n",
    "SPLIT = 'test'\n",
    "\n",
    "# Whisper model name, can be one of the following: tiny/tiny.en/base/base.en/small/small.en/medium/medium.en\n",
    "WHISPER_MODEL = 'tiny'\n",
    "\n",
    "import torch\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e923c71-af64-4226-a69d-b188cf0efdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained OpenAI Whisper model\n",
    "import whisper\n",
    "\n",
    "model = whisper.load_model(WHISPER_MODEL).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51258184-1972-4182-84cd-5586c56dcf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rm2114/rds/rds-altaslp-8YSp2LXTlkY/experiments/rm2114/espnet_mr/tools/anaconda/envs/adv_attack/lib/python3.9/site-packages/datasets/load.py:1486: FutureWarning: The repository for google/fleurs contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/google/fleurs\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'num_samples', 'path', 'audio', 'transcription', 'raw_transcription', 'gender', 'lang_id', 'language', 'lang_group_id'],\n",
       "    num_rows: 647\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Automatically download and load Huggingface dataset\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(DATASET, LANGUAGE, split=SPLIT)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba8720ca-3afe-4d44-8e58-eaf872bd1dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rm2114/rds/rds-altaslp-8YSp2LXTlkY/data/cache/huggingface/datasets/downloads/extracted/e4f5d19baa90b5c1695d901b38c256e3bb4d0a31c797316be281b6425c5b1ace/test/14115239728007650784.wav'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a random sample from the testset and print the reference \n",
    "import random, os\n",
    "idx = random.randint(0, len(dataset)-1)\n",
    "\n",
    "# Prepare the path of the selected utterance\n",
    "audio_path = os.path.join(os.path.dirname(dataset[idx]['path']), dataset[idx]['audio']['path'])\n",
    "audio_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e218fee7-98e5-47c0-958b-8fe8ff677374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASR reference: \"on the other hand icy and snowy conditions are normal in many countries and traffic goes on mostly uninterrupted all year round\"\n"
     ]
    }
   ],
   "source": [
    "# The reference transcription for the utterance\n",
    "print(f'ASR reference: \"{dataset[idx][\"transcription\"]}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b6c91f2-2450-4094-be1f-2a47ba100479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the utterance\n",
    "from whisper.audio import load_audio\n",
    "\n",
    "audio = load_audio(audio_path)\n",
    "audio = torch.from_numpy(audio).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2225abce-c2dc-4b0a-82b5-dade499fe9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rm2114/rds/rds-altaslp-8YSp2LXTlkY/experiments/rm2114/espnet_mr/tools/anaconda/envs/adv_attack/lib/python3.9/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "\n",
      "Default Whisper transcription: \" On the other hand, I see a snowy conditions are normal in many countries and the traffic goes on most unneruptly all year round.\"\n"
     ]
    }
   ],
   "source": [
    "# Whisepr transcription for the original speech signal\n",
    "print(f'Default Whisper transcription: \"{model.transcribe(audio)[\"text\"]}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22cfee35-292a-47d9-b273-73d187cf0f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the relevant universal acoustic adversarial attack segment (0.64 seconds in length)\n",
    "import numpy as np\n",
    "\n",
    "loaded_array = np.load(f'audio_attack_segments/{WHISPER_MODEL}.np.npy')\n",
    "audio_attack_segment = torch.from_numpy(loaded_array).to(audio.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3a26504-a501-4a67-9e10-6663b9d1c28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepend the learned universal attack segment to the original speech signal\n",
    "audio_with_prompts = torch.cat((audio_attack_segment, audio), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b88e8ac-83fe-4aab-b374-cee7968eb019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "\n",
      "Whisper transcription with the learned attack segment: \"\"\n"
     ]
    }
   ],
   "source": [
    "# Whisepr transcription for the concatenated speech signal\n",
    "# Whisper is \"muted\" in this case\n",
    "print(f'Whisper transcription with the learned attack segment: \"{model.transcribe(audio_with_prompts)[\"text\"]}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff202fe-d91c-473d-ac0c-6e4d1b4b2e91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
